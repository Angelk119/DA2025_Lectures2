{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Challenge 13 â€” Interpreting Logistic Regression \n",
    "\n",
    "**Purpose**  \n",
    "Apply what you learned about logistic regression interpretation by analyzing NYC Restaurant Inspection data. \n",
    " \n",
    "Youâ€™ll practice interpreting **continuous**, **binary**, and **categorical** predictors, compute **odds ratios**, and assess model accuracy. \n",
    "\n",
    "**Learning Goals**\n",
    "- Convert coefficients to odds ratios using `np.exp()`.  \n",
    "- Interpret ORs for continuous, binary, and categorical predictors.  \n",
    "- Use accuracy to assess logistic regression performance.  \n",
    "- Communicate results clearly and responsibly.  \n",
    "\n",
    "**Data:** June 1, 2025 - Nov 4, 2025 Restaurant Health Inspection\n",
    "\n",
    "[Restaurant Health Inspection](https://data.cityofnewyork.us/Health/DOHMH-New-York-City-Restaurant-Inspection-Results/43nn-pn8j/about_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructor Guidance\n",
    "\n",
    "**Hint: Use the Lecture Deck, Canvas Reading, and Docs to help you with the code**\n",
    "\n",
    "Use this guide live; students implement below.\n",
    "\n",
    "**Docs (Quick Links)**\n",
    "- LogisticRegression â€” https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html  \n",
    "- accuracy_score â€” https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html  \n",
    "- OneHotEncoder â€” https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html  \n",
    "- StandardScaler â€” https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html  \n",
    "- np.exp â€” https://numpy.org/doc/stable/reference/generated/numpy.exp.html  \n",
    "\n",
    "**Pseudocode Plan**\n",
    "\n",
    "1ï¸âƒ£ Load cleaned restaurant inspection data from the previous challenge.  \n",
    "2ï¸âƒ£ Define target = `IS_A` (1 = Grade A, 0 = otherwise).  \n",
    "3ï¸âƒ£ Predictors â†’  \n",
    "    â€¢ Continuous = `SCORE`  \n",
    "    â€¢ Binary = `CRITICAL_NUM`  \n",
    "    â€¢ Categorical = `BORO`  \n",
    "4ï¸âƒ£ Scale continuous variables; encode categorical ones.  \n",
    "5ï¸âƒ£ Fit `LogisticRegression`.  \n",
    "6ï¸âƒ£ Exponentiate coefficients (np.exp()) â†’ odds ratios.  \n",
    "7ï¸âƒ£ Interpret one continuous, one binary, and one categorical coefficient.  \n",
    "8ï¸âƒ£ Evaluate accuracy.  \n",
    "9ï¸âƒ£ Reflect on scaling choices and communication of odds.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You Do â€” Student Section\n",
    "Work in pairs. Comment your choices briefly. Keep code simpleâ€”only coerce the columns you use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 â€” Imports and Plot Defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from pathlib import Path\n",
    "pd.set_option('display.float_format', lambda x: f'{x:,.4f}')\n",
    "#Some of these imports may not be used but they are just here just in case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 â€” Load CSV, Create Columns, Preview\n",
    "\n",
    "- Point to your New York City Restaurant Inspection Data \n",
    "- Create the `is_A` and `critical_num` columns like you did in L11 notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((130948, 27),\n",
       " ['CAMIS',\n",
       "  'DBA',\n",
       "  'BORO',\n",
       "  'BUILDING',\n",
       "  'STREET',\n",
       "  'ZIPCODE',\n",
       "  'PHONE',\n",
       "  'CUISINE DESCRIPTION',\n",
       "  'INSPECTION DATE',\n",
       "  'ACTION',\n",
       "  'VIOLATION CODE',\n",
       "  'VIOLATION DESCRIPTION',\n",
       "  'CRITICAL FLAG',\n",
       "  'SCORE',\n",
       "  'GRADE',\n",
       "  'GRADE DATE',\n",
       "  'RECORD DATE',\n",
       "  'INSPECTION TYPE',\n",
       "  'Latitude',\n",
       "  'Longitude',\n",
       "  'Community Board',\n",
       "  'Council District',\n",
       "  'Census Tract',\n",
       "  'BIN',\n",
       "  'BBL',\n",
       "  'NTA',\n",
       "  'Location'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/gabriel/Desktop/marcy/DA2025_Lectures2/Mod6/data/DOHMH_New_York_City_Restaurant_Inspection_Results_20251104 copy.csv', low_memory=False)\n",
    "df = df.dropna()\n",
    "(df.shape, df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.replace('NAN', np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned.dropna(subset=['GRADE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      SCORE GRADE  is_A  critical_num\n",
      "171 34.0000     C     0             1\n",
      "172  4.0000     P     0             0\n",
      "179 28.0000     Z     0             0\n",
      "200 17.0000     B     0             1\n",
      "210 55.0000     Z     0             0\n",
      "CAMIS                      int64\n",
      "DBA                       object\n",
      "BORO                      object\n",
      "BUILDING                  object\n",
      "STREET                    object\n",
      "ZIPCODE                  float64\n",
      "PHONE                     object\n",
      "CUISINE DESCRIPTION       object\n",
      "INSPECTION DATE           object\n",
      "ACTION                    object\n",
      "VIOLATION CODE            object\n",
      "VIOLATION DESCRIPTION     object\n",
      "CRITICAL FLAG             object\n",
      "SCORE                    float64\n",
      "GRADE                     object\n",
      "GRADE DATE                object\n",
      "RECORD DATE               object\n",
      "INSPECTION TYPE           object\n",
      "Latitude                 float64\n",
      "Longitude                float64\n",
      "Community Board          float64\n",
      "Council District         float64\n",
      "Census Tract             float64\n",
      "BIN                      float64\n",
      "BBL                      float64\n",
      "NTA                       object\n",
      "Location                  object\n",
      "is_A                       int64\n",
      "critical_num               int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['SCORE'] = pd.to_numeric(df['SCORE'], errors='coerce')\n",
    "df = df.dropna(subset=['SCORE'])\n",
    "\n",
    "# Standardize GRADE and CRITICAL FLAG columns to uppercase text\n",
    "df['GRADE'] = df['GRADE'].astype(str).str.strip().str.upper()\n",
    "\n",
    "df['CRITICAL FLAG'] = df['CRITICAL FLAG'].astype(str).str.strip().str.upper()\n",
    "\n",
    "# Create binary variables \n",
    "df['is_A'] = (df['GRADE'] == 'A').astype(int)\n",
    "df['critical_num'] = (df['CRITICAL FLAG'] == 'CRITICAL').astype(int)\n",
    "\n",
    "print(df[['SCORE', 'GRADE', 'is_A', 'critical_num']].head())\n",
    "print(df.dtypes)\n",
    "df_cleaned = df[['SCORE', 'GRADE', 'is_A', 'critical_num']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SCORE', 'GRADE', 'is_A', 'critical_num']\n"
     ]
    }
   ],
   "source": [
    "print(df_cleaned.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "critical_num\n",
       "1    65818\n",
       "0    65130\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned['critical_num'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 â€” Define Predictors & Target\n",
    "\n",
    "- Target is `is_A` \n",
    "- X predictors are: SCORE, CRITICAL_NUM (created in Step 2), BORO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['SCORE', 'critical_num', 'BORO']]\n",
    "y = df['is_A']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 â€” Split Data (70/30 Stratify by Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.3, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 â€“ Preprocessing (You can chose to do this in a Pipeline)  \n",
    "\n",
    "- Scale continuous features  \n",
    "- Pass binary as is  \n",
    "- One-hot encode categorical feature (`BORO`)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with pd.get_dummies\n",
      "      SCORE  critical_num       BORO  BORO_Brooklyn  BORO_Manhattan  \\\n",
      "171 34.0000             1   Brooklyn           True           False   \n",
      "172  4.0000             0  Manhattan          False            True   \n",
      "179 28.0000             0   Brooklyn           True           False   \n",
      "200 17.0000             1     Queens          False           False   \n",
      "210 55.0000             0   Brooklyn           True           False   \n",
      "\n",
      "     BORO_Queens  BORO_Staten Island  \n",
      "171        False               False  \n",
      "172        False               False  \n",
      "179        False               False  \n",
      "200         True               False  \n",
      "210        False               False  \n"
     ]
    }
   ],
   "source": [
    "dummies_pd = pd.get_dummies(X['BORO'], drop_first=True, prefix='BORO')\n",
    "X = pd.concat([X, dummies_pd], axis=1)\n",
    "print(\"Data with pd.get_dummies\")\n",
    "print(X.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df['critical_num'] = scaler.fit_transform(df[['critical_num']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 â€“ Fit Model & Evaluate Accuracy\n",
    "\n",
    "- Fit `is_A ~ score` using **LogisticRegression**  \n",
    "- Compute predictions with `.predict()`  \n",
    "- Evaluate accuracy with `accuracy_score()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Logistic Regression - Scaled SCORE + is_A): 0.9756904670994018\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = df[['SCORE']]\n",
    "y = df['is_A']\n",
    "\n",
    "# Split data (reuse if already done)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Fit logistic regression model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy (Logistic Regression - Scaled SCORE + is_A):\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 â€“ Extract Coefficients and Convert to Odds Ratios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BORO: Bronx\n",
      "Intercept (Log-Odds): 11.5279\n",
      "Coefficient (Log-Odds): -0.7128\n",
      "Baseline Odds: 101512.7242\n",
      "Odds Ratio for 'score': 0.4903\n",
      "\n",
      "BORO: Brooklyn\n",
      "Intercept (Log-Odds): 10.5522\n",
      "Coefficient (Log-Odds): -0.6431\n",
      "Baseline Odds: 38260.1304\n",
      "Odds Ratio for 'score': 0.5257\n",
      "\n",
      "BORO: Manhattan\n",
      "Intercept (Log-Odds): 12.8172\n",
      "Coefficient (Log-Odds): -0.7995\n",
      "Baseline Odds: 368493.5739\n",
      "Odds Ratio for 'score': 0.4496\n",
      "\n",
      "BORO: Queens\n",
      "Intercept (Log-Odds): 11.2183\n",
      "Coefficient (Log-Odds): -0.6876\n",
      "Baseline Odds: 74479.2283\n",
      "Odds Ratio for 'score': 0.5028\n",
      "\n",
      "BORO: Staten Island\n",
      "Intercept (Log-Odds): 14.1271\n",
      "Coefficient (Log-Odds): -0.8936\n",
      "Baseline Odds: 1365626.0435\n",
      "Odds Ratio for 'score': 0.4092\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "# Loop through each BORO group\n",
    "for boro, group in df.groupby('BORO'):\n",
    "    X = group[['SCORE']]\n",
    "    y = group['is_A']\n",
    "    \n",
    "    # Fit logistic regression for that borough\n",
    "    log_reg = LogisticRegression()\n",
    "    log_reg.fit(X, y)\n",
    "    \n",
    "    coef = log_reg.coef_[0][0]\n",
    "    intercept = log_reg.intercept_[0]\n",
    "    \n",
    "    baseline_odds = np.exp(intercept)\n",
    "    odds_ratio = np.exp(coef)\n",
    "    \n",
    "    print(f\"\\nBORO: {boro}\")\n",
    "    print(f\"Intercept (Log-Odds): {intercept:.4f}\")\n",
    "    print(f\"Coefficient (Log-Odds): {coef:.4f}\")\n",
    "    print(f\"Baseline Odds: {baseline_odds:.4f}\")\n",
    "    print(f\"Odds Ratio for 'score': {odds_ratio:.4f}\")\n",
    "    \n",
    "    results.append({\n",
    "        'BORO': boro,\n",
    "        'Intercept (Log-Odds)': intercept,\n",
    "        'Coefficient (Log-Odds)': coef,\n",
    "        'Baseline Odds': baseline_odds,\n",
    "        'Odds Ratio (score)': odds_ratio\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            BORO  Intercept (Log-Odds)  Coefficient (Log-Odds)  Baseline Odds  \\\n",
      "0          Bronx               11.5279                 -0.7128   101,512.7242   \n",
      "1       Brooklyn               10.5522                 -0.6431    38,260.1304   \n",
      "2      Manhattan               12.8172                 -0.7995   368,493.5739   \n",
      "3         Queens               11.2183                 -0.6876    74,479.2283   \n",
      "4  Staten Island               14.1271                 -0.8936 1,365,626.0435   \n",
      "\n",
      "   Odds Ratio (score)  \n",
      "0              0.4903  \n",
      "1              0.5257  \n",
      "2              0.4496  \n",
      "3              0.5028  \n",
      "4              0.4092  \n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8 â€“ Interpret Each Predictor \n",
    "\n",
    "**Remember**\n",
    "ðŸ’¡ OR > 1 â†’ increases odds of Grade A  \n",
    "ðŸ’¡ OR < 1 â†’ decreases odds of Grade A\n",
    "\n",
    "**Type markdown interpreting all 3 predictors in plain english**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Students (or cases) with higher scores are more likely to receive a Grade A if OR > 1, and less likely if OR < 1.\n",
    "\n",
    "A higher critical_num value is associated with a higher (if OR > 1) or lower (if OR < 1) likelihood of earning a Grade A.\n",
    "\n",
    "Students (or observations) from certain boroughs have higher or lower odds of earning a Grade A compared to the reference borough, depending on each boroughâ€™s odds ratio.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We Share â€” Reflection & Wrap-Up\n",
    "\n",
    "Write **one short paragraphs** (4â€“6 sentences). Be specific and use evidence from your notebook.\n",
    "\n",
    "**Which predictor had the strongest relationship with getting an A grade?**  \n",
    "Use the odds ratios and accuracy to support your answer.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the predictors, SCORE had the strongest relationship with earning a Grade A.\n",
    "A higher score substantially increased the odds of receiving an A, even after accounting for critical_num and BORO.\n",
    "The effects of critical_num and differences across BOROs were comparatively smaller."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
